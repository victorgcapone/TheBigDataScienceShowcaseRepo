{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In this notebook we will compare traditional NN\n",
    "# and CNN for the MNIST Digits dataset using tensorflow\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train),(x_test, y_test) = keras.datasets.mnist.load_data()\n",
    "x_train, x_test = x_train / 255.0, x_test / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(x_train[3], cmap='gray')\n",
    "print(y_train[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's create our traditional NN\n",
    "nn = keras.models.Sequential([\n",
    "    keras.layers.Flatten(), # Flatten the 28x28 images\n",
    "    keras.layers.Dense(518, activation=tf.nn.relu), # First hidden layer, 512 neurons, ReLU activation\n",
    "    keras.layers.Dense(10, activation=tf.nn.softmax) # output Layer, 10 categories (0-9) and softmax activation\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "60000/60000 [==============================] - 13s 214us/step - loss: 0.1973 - acc: 0.9416\n",
      "Epoch 2/5\n",
      "60000/60000 [==============================] - 10s 162us/step - loss: 0.0800 - acc: 0.9758\n",
      "Epoch 3/5\n",
      "60000/60000 [==============================] - 12s 192us/step - loss: 0.0535 - acc: 0.9830\n",
      "Epoch 4/5\n",
      "60000/60000 [==============================] - 11s 178us/step - loss: 0.0353 - acc: 0.9887\n",
      "Epoch 5/5\n",
      "60000/60000 [==============================] - 10s 170us/step - loss: 0.0274 - acc: 0.9916\n",
      "10000/10000 [==============================] - 1s 53us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.06767449411806592, 0.9801]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compile, fit and evaluate our model\n",
    "nn.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "nn.fit(x_train, y_train, epochs=5)\n",
    "nn.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Okay, let's now create a cNN without using Keras API\n",
    "def create_model(training):\n",
    "    # First, reshape ou 28x28 graymap images to 28x28x1 (single channel)\n",
    "    reshape = tf.reshape(X, [-1, 28,28, 1])\n",
    "    # Two convolutions layers with ReLU activation\n",
    "    conv_1 = tf.layers.conv2d(reshape, activation=tf.nn.relu, filters=32, kernel_size=(3,3))\n",
    "    conv_2 = tf.layers.conv2d(conv_1, activation=tf.nn.relu, filters=64, kernel_size=(3,3))\n",
    "    # Max Pooling layer\n",
    "    pool_1 = tf.layers.max_pooling2d(conv_2, pool_size=(2,2), strides=(1,1))\n",
    "    # Dropout to mitigate overfitting\n",
    "    dropout_1 = tf.layers.dropout(pool_1, rate=0.25, training=training)\n",
    "    # Flatten results for dense layers\n",
    "    flat_1  = tf.layers.flatten(dropout_1)\n",
    "    # Dense (Fully connected) layer\n",
    "    dense_1 = tf.layers.dense(flat_1, units=128, activation='relu')\n",
    "    # Output has 10 classes\n",
    "    output = tf.layers.dense(dense_1, units=10, activation='softmax', name='output')\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_model(model, labels):\n",
    "    # Mean crossentropy as the loss function\n",
    "    xentropy =  keras.losses.sparse_categorical_crossentropy(y_pred=model, y_true=labels)\n",
    "    loss = tf.reduce_mean(xentropy)\n",
    "    # Setting our optmizer parameters\n",
    "    optmizer = tf.train.MomentumOptimizer(learning_rate=0.01, momentum=0.9)\n",
    "    training_op = optmizer.minimize(loss)\n",
    "    return training_op"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining our placeholders \n",
    "# Input is a lot of images (None) with dimensions 28x28, \n",
    "# the channel dimensions is set by the reshape layer in the model\n",
    "X = tf.placeholder(tf.float32, shape=[None, 28, 28])\n",
    "# Output shape can be infered\n",
    "y = tf.placeholder(tf.int32, shape=[None])\n",
    "# Are we training the model? Used by the dropout layer\n",
    "training = tf.placeholder(tf.bool)\n",
    "# Create the model\n",
    "model = create_model(training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initializing our model\n",
    "final_model = init_model(model, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# running TF training\n",
    "init = tf.global_variables_initializer()\n",
    "session = tf.Session()\n",
    "session.run(init)\n",
    "# Accuracy logging\n",
    "correct = tf.nn.in_top_k(model, y, 1)\n",
    "accuracy = tf.reduce_mean(tf.cast(correct, tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def yield_mb(x, y, batchsize=1000):\n",
    "    batches = int(len(x)/batchsize)\n",
    "    for i in range(batches):\n",
    "        yield (x[i*batchsize:(i+1)*batchsize], y[i*batchsize:(i+1)*batchsize])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy: 0.9855\n",
      "Train accuracy: 0.979\n",
      "Train accuracy: 0.9895\n",
      "Train accuracy: 0.996\n",
      "Train accuracy: 0.992\n",
      "CPU times: user 41min 34s, sys: 3min 13s, total: 44min 48s\n",
      "Wall time: 23min 19s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Main training loop: 57s\n",
    "for test_data, test_label in yield_mb(x_test, y_test, batchsize=2000):\n",
    "    for data, label in yield_mb(x_train, y_train, batchsize=64):\n",
    "        # Make sure to run the `final_model` as it includes the optmization step\n",
    "        session.run(final_model, feed_dict={X: data, y: label, training: True})\n",
    "    # Log\n",
    "    acc_train = session.run(accuracy, feed_dict={X: test_data, y: test_label, training: True})\n",
    "    print(\"Train accuracy:\", acc_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
